| distributed init (rank 0): env://, gpu 0
| distributed init (rank 3): env://, gpu 3
| distributed init (rank 5): env://, gpu 5
| distributed init (rank 2): env://, gpu 2
| distributed init (rank 4): env://, gpu 4
| distributed init (rank 1): env://, gpu 1
[11:55:03.603301] job dir: /home/xts/code/SNN/QSD-Transformer/classification
[11:55:03.603432] Namespace(batch_size=196,
epochs=200,
accum_iter=1,
finetune='/home/xts/code/SNN/QSD-Transformer/classification/out/att_no_conv3/best_checkpoint.pth',
data_path='/opt/dataset/imagenet/',
model='spikformer_8_15M_CAFormer_less_conv',
model_mode='ms',
input_size=224,
drop_path=0.1,
clip_grad=None,
weight_decay=0.05,
lr=None,
blr=0.0003,
layer_decay=1.0,
min_lr=1e-06,
warmup_epochs=10,
color_jitter=None,
aa='rand-m9-mstd0.5-inc1',
smoothing=0.1,
reprob=0.25,
remode='pixel',
recount=1,
resplit=False,
mixup=0,
cutmix=0,
cutmix_minmax=None,
mixup_prob=1.0,
mixup_switch_prob=0.5,
mixup_mode='batch',
global_pool=True,
time_steps=1,
nb_classes=1000,
output_dir='./out/att_no_conv3_less_conv',
log_dir='./out/att_no_conv3_less_conv',
device='cuda',
seed=0,
MODEL_EMA=True,
MODEL_EMA_DECAY=0.99996,
resume=None,
start_epoch=None,
eval=False,
dist_eval=True,
num_workers=8,
pin_mem=True,
world_size=6,
local_rank=-1,
dist_on_itp=False,
dist_url='env://',
wbit=32,
rank=0,
gpu=0,
distributed=True,
dist_backend='nccl')
[11:55:06.853509] Dataset ImageFolder
    Number of datapoints: 1281167
    Root location: /opt/dataset/imagenet/train
    StandardTransform
Transform: Compose(
               RandomResizedCropAndInterpolation(size=(224, 224), scale=(0.08, 1.0), ratio=(0.75, 1.3333), interpolation=bicubic)
               RandomHorizontalFlip(p=0.5)
               RandAugment(n=2, ops=
           	AugmentOp(name=AutoContrast, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=Equalize, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=Invert, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=Rotate, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=PosterizeIncreasing, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=SolarizeIncreasing, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=SolarizeAdd, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=ColorIncreasing, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=ContrastIncreasing, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=BrightnessIncreasing, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=SharpnessIncreasing, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=ShearX, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=ShearY, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=TranslateXRel, p=0.5, m=9, mstd=0.5)
           	AugmentOp(name=TranslateYRel, p=0.5, m=9, mstd=0.5))
               ToTensor()
               Normalize(mean=tensor([0.4850, 0.4560, 0.4060]), std=tensor([0.2290, 0.2240, 0.2250]))
               RandomErasing(p=0.25, mode=pixel, count=(1, 1))
           )
[11:55:07.498266] Dataset ImageFolder
    Number of datapoints: 50000
    Root location: /opt/dataset/imagenet/val
    StandardTransform
Transform: Compose(
               Resize(size=256, interpolation=bicubic, max_size=None, antialias=True)
               CenterCrop(size=(224, 224))
               ToTensor()
               Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))
           )
[11:55:07.498632] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f14ef572b30>
[11:55:07.498674] Warning: Enabling distributed evaluation with an eval dataset not divisible by process number. This will slightly alter validation results as extra duplicate entries are added to achieve equal num of samples per-process.
[11:55:07.775040] Load pre-trained checkpoint from: /home/xts/code/SNN/QSD-Transformer/classification/out/att_no_conv3/best_checkpoint.pth
[11:55:07.799071] _IncompatibleKeys(missing_keys=['block2.0.layer_scale1', 'block2.0.layer_scale2', 'block2.0.attn.q_conv.weight', 'block2.0.attn.q_conv.alpha', 'block2.0.attn.q_conv.init_state', 'block2.0.attn.q_conv.act.alpha', 'block2.0.attn.q_conv.act.zero_point', 'block2.0.attn.q_conv.act.init_state', 'block2.0.attn.q_conv.act.signed', 'block2.0.attn.k_conv.weight', 'block2.0.attn.k_conv.alpha', 'block2.0.attn.k_conv.init_state', 'block2.0.attn.k_conv.act.alpha', 'block2.0.attn.k_conv.act.zero_point', 'block2.0.attn.k_conv.act.init_state', 'block2.0.attn.k_conv.act.signed', 'block2.0.attn.v_conv.weight', 'block2.0.attn.v_conv.alpha', 'block2.0.attn.v_conv.init_state', 'block2.0.attn.v_conv.act.alpha', 'block2.0.attn.v_conv.act.zero_point', 'block2.0.attn.v_conv.act.init_state', 'block2.0.attn.v_conv.act.signed', 'block2.0.attn.proj_conv.0.weight', 'block2.0.attn.proj_conv.0.alpha', 'block2.0.attn.proj_conv.0.init_state', 'block2.0.attn.proj_conv.0.act.alpha', 'block2.0.attn.proj_conv.0.act.zero_point', 'block2.0.attn.proj_conv.0.act.init_state', 'block2.0.attn.proj_conv.0.act.signed', 'block2.0.attn.proj_conv.1.weight', 'block2.0.attn.proj_conv.1.bias', 'block2.0.attn.proj_conv.1.running_mean', 'block2.0.attn.proj_conv.1.running_var', 'block2.0.mlp.fc1_conv.weight', 'block2.0.mlp.fc1_conv.bias', 'block2.0.mlp.fc1_conv.alpha', 'block2.0.mlp.fc1_conv.init_state', 'block2.0.mlp.fc1_conv.act.alpha', 'block2.0.mlp.fc1_conv.act.zero_point', 'block2.0.mlp.fc1_conv.act.init_state', 'block2.0.mlp.fc1_conv.act.signed', 'block2.0.mlp.fc1_bn.weight', 'block2.0.mlp.fc1_bn.bias', 'block2.0.mlp.fc1_bn.running_mean', 'block2.0.mlp.fc1_bn.running_var', 'block2.0.mlp.fc2_conv.weight', 'block2.0.mlp.fc2_conv.bias', 'block2.0.mlp.fc2_conv.alpha', 'block2.0.mlp.fc2_conv.init_state', 'block2.0.mlp.fc2_conv.act.alpha', 'block2.0.mlp.fc2_conv.act.zero_point', 'block2.0.mlp.fc2_conv.act.init_state', 'block2.0.mlp.fc2_conv.act.signed', 'block2.0.mlp.fc2_bn.weight', 'block2.0.mlp.fc2_bn.bias', 'block2.0.mlp.fc2_bn.running_mean', 'block2.0.mlp.fc2_bn.running_var', 'block2.1.layer_scale1', 'block2.1.layer_scale2', 'block2.1.attn.q_conv.weight', 'block2.1.attn.q_conv.alpha', 'block2.1.attn.q_conv.init_state', 'block2.1.attn.q_conv.act.alpha', 'block2.1.attn.q_conv.act.zero_point', 'block2.1.attn.q_conv.act.init_state', 'block2.1.attn.q_conv.act.signed', 'block2.1.attn.k_conv.weight', 'block2.1.attn.k_conv.alpha', 'block2.1.attn.k_conv.init_state', 'block2.1.attn.k_conv.act.alpha', 'block2.1.attn.k_conv.act.zero_point', 'block2.1.attn.k_conv.act.init_state', 'block2.1.attn.k_conv.act.signed', 'block2.1.attn.v_conv.weight', 'block2.1.attn.v_conv.alpha', 'block2.1.attn.v_conv.init_state', 'block2.1.attn.v_conv.act.alpha', 'block2.1.attn.v_conv.act.zero_point', 'block2.1.attn.v_conv.act.init_state', 'block2.1.attn.v_conv.act.signed', 'block2.1.attn.proj_conv.0.weight', 'block2.1.attn.proj_conv.0.alpha', 'block2.1.attn.proj_conv.0.init_state', 'block2.1.attn.proj_conv.0.act.alpha', 'block2.1.attn.proj_conv.0.act.zero_point', 'block2.1.attn.proj_conv.0.act.init_state', 'block2.1.attn.proj_conv.0.act.signed', 'block2.1.attn.proj_conv.1.weight', 'block2.1.attn.proj_conv.1.bias', 'block2.1.attn.proj_conv.1.running_mean', 'block2.1.attn.proj_conv.1.running_var', 'block2.1.mlp.fc1_conv.weight', 'block2.1.mlp.fc1_conv.bias', 'block2.1.mlp.fc1_conv.alpha', 'block2.1.mlp.fc1_conv.init_state', 'block2.1.mlp.fc1_conv.act.alpha', 'block2.1.mlp.fc1_conv.act.zero_point', 'block2.1.mlp.fc1_conv.act.init_state', 'block2.1.mlp.fc1_conv.act.signed', 'block2.1.mlp.fc1_bn.weight', 'block2.1.mlp.fc1_bn.bias', 'block2.1.mlp.fc1_bn.running_mean', 'block2.1.mlp.fc1_bn.running_var', 'block2.1.mlp.fc2_conv.weight', 'block2.1.mlp.fc2_conv.bias', 'block2.1.mlp.fc2_conv.alpha', 'block2.1.mlp.fc2_conv.init_state', 'block2.1.mlp.fc2_conv.act.alpha', 'block2.1.mlp.fc2_conv.act.zero_point', 'block2.1.mlp.fc2_conv.act.init_state', 'block2.1.mlp.fc2_conv.act.signed', 'block2.1.mlp.fc2_bn.weight', 'block2.1.mlp.fc2_bn.bias', 'block2.1.mlp.fc2_bn.running_mean', 'block2.1.mlp.fc2_bn.running_var', 'block2.2.layer_scale1', 'block2.2.layer_scale2', 'block2.2.attn.q_conv.weight', 'block2.2.attn.q_conv.alpha', 'block2.2.attn.q_conv.init_state', 'block2.2.attn.q_conv.act.alpha', 'block2.2.attn.q_conv.act.zero_point', 'block2.2.attn.q_conv.act.init_state', 'block2.2.attn.q_conv.act.signed', 'block2.2.attn.k_conv.weight', 'block2.2.attn.k_conv.alpha', 'block2.2.attn.k_conv.init_state', 'block2.2.attn.k_conv.act.alpha', 'block2.2.attn.k_conv.act.zero_point', 'block2.2.attn.k_conv.act.init_state', 'block2.2.attn.k_conv.act.signed', 'block2.2.attn.v_conv.weight', 'block2.2.attn.v_conv.alpha', 'block2.2.attn.v_conv.init_state', 'block2.2.attn.v_conv.act.alpha', 'block2.2.attn.v_conv.act.zero_point', 'block2.2.attn.v_conv.act.init_state', 'block2.2.attn.v_conv.act.signed', 'block2.2.attn.proj_conv.0.weight', 'block2.2.attn.proj_conv.0.alpha', 'block2.2.attn.proj_conv.0.init_state', 'block2.2.attn.proj_conv.0.act.alpha', 'block2.2.attn.proj_conv.0.act.zero_point', 'block2.2.attn.proj_conv.0.act.init_state', 'block2.2.attn.proj_conv.0.act.signed', 'block2.2.attn.proj_conv.1.weight', 'block2.2.attn.proj_conv.1.bias', 'block2.2.attn.proj_conv.1.running_mean', 'block2.2.attn.proj_conv.1.running_var', 'block2.2.mlp.fc1_conv.weight', 'block2.2.mlp.fc1_conv.bias', 'block2.2.mlp.fc1_conv.alpha', 'block2.2.mlp.fc1_conv.init_state', 'block2.2.mlp.fc1_conv.act.alpha', 'block2.2.mlp.fc1_conv.act.zero_point', 'block2.2.mlp.fc1_conv.act.init_state', 'block2.2.mlp.fc1_conv.act.signed', 'block2.2.mlp.fc1_bn.weight', 'block2.2.mlp.fc1_bn.bias', 'block2.2.mlp.fc1_bn.running_mean', 'block2.2.mlp.fc1_bn.running_var', 'block2.2.mlp.fc2_conv.weight', 'block2.2.mlp.fc2_conv.bias', 'block2.2.mlp.fc2_conv.alpha', 'block2.2.mlp.fc2_conv.init_state', 'block2.2.mlp.fc2_conv.act.alpha', 'block2.2.mlp.fc2_conv.act.zero_point', 'block2.2.mlp.fc2_conv.act.init_state', 'block2.2.mlp.fc2_conv.act.signed', 'block2.2.mlp.fc2_bn.weight', 'block2.2.mlp.fc2_bn.bias', 'block2.2.mlp.fc2_bn.running_mean', 'block2.2.mlp.fc2_bn.running_var', 'block2.3.layer_scale1', 'block2.3.layer_scale2', 'block2.3.attn.q_conv.weight', 'block2.3.attn.q_conv.alpha', 'block2.3.attn.q_conv.init_state', 'block2.3.attn.q_conv.act.alpha', 'block2.3.attn.q_conv.act.zero_point', 'block2.3.attn.q_conv.act.init_state', 'block2.3.attn.q_conv.act.signed', 'block2.3.attn.k_conv.weight', 'block2.3.attn.k_conv.alpha', 'block2.3.attn.k_conv.init_state', 'block2.3.attn.k_conv.act.alpha', 'block2.3.attn.k_conv.act.zero_point', 'block2.3.attn.k_conv.act.init_state', 'block2.3.attn.k_conv.act.signed', 'block2.3.attn.v_conv.weight', 'block2.3.attn.v_conv.alpha', 'block2.3.attn.v_conv.init_state', 'block2.3.attn.v_conv.act.alpha', 'block2.3.attn.v_conv.act.zero_point', 'block2.3.attn.v_conv.act.init_state', 'block2.3.attn.v_conv.act.signed', 'block2.3.attn.proj_conv.0.weight', 'block2.3.attn.proj_conv.0.alpha', 'block2.3.attn.proj_conv.0.init_state', 'block2.3.attn.proj_conv.0.act.alpha', 'block2.3.attn.proj_conv.0.act.zero_point', 'block2.3.attn.proj_conv.0.act.init_state', 'block2.3.attn.proj_conv.0.act.signed', 'block2.3.attn.proj_conv.1.weight', 'block2.3.attn.proj_conv.1.bias', 'block2.3.attn.proj_conv.1.running_mean', 'block2.3.attn.proj_conv.1.running_var', 'block2.3.mlp.fc1_conv.weight', 'block2.3.mlp.fc1_conv.bias', 'block2.3.mlp.fc1_conv.alpha', 'block2.3.mlp.fc1_conv.init_state', 'block2.3.mlp.fc1_conv.act.alpha', 'block2.3.mlp.fc1_conv.act.zero_point', 'block2.3.mlp.fc1_conv.act.init_state', 'block2.3.mlp.fc1_conv.act.signed', 'block2.3.mlp.fc1_bn.weight', 'block2.3.mlp.fc1_bn.bias', 'block2.3.mlp.fc1_bn.running_mean', 'block2.3.mlp.fc1_bn.running_var', 'block2.3.mlp.fc2_conv.weight', 'block2.3.mlp.fc2_conv.bias', 'block2.3.mlp.fc2_conv.alpha', 'block2.3.mlp.fc2_conv.init_state', 'block2.3.mlp.fc2_conv.act.alpha', 'block2.3.mlp.fc2_conv.act.zero_point', 'block2.3.mlp.fc2_conv.act.init_state', 'block2.3.mlp.fc2_conv.act.signed', 'block2.3.mlp.fc2_bn.weight', 'block2.3.mlp.fc2_bn.bias', 'block2.3.mlp.fc2_bn.running_mean', 'block2.3.mlp.fc2_bn.running_var'], unexpected_keys=['ConvBlock2_1.0.Conv.pwconv1.weight', 'ConvBlock2_1.0.Conv.pwconv1.alpha', 'ConvBlock2_1.0.Conv.pwconv1.init_state', 'ConvBlock2_1.0.Conv.pwconv1.act.alpha', 'ConvBlock2_1.0.Conv.pwconv1.act.zero_point', 'ConvBlock2_1.0.Conv.pwconv1.act.init_state', 'ConvBlock2_1.0.Conv.pwconv1.act.signed', 'ConvBlock2_1.0.Conv.bn1.weight', 'ConvBlock2_1.0.Conv.bn1.bias', 'ConvBlock2_1.0.Conv.bn1.running_mean', 'ConvBlock2_1.0.Conv.bn1.running_var', 'ConvBlock2_1.0.Conv.bn1.num_batches_tracked', 'ConvBlock2_1.0.Conv.dwconv.weight', 'ConvBlock2_1.0.Conv.dwconv.alpha', 'ConvBlock2_1.0.Conv.dwconv.init_state', 'ConvBlock2_1.0.Conv.dwconv.act.alpha', 'ConvBlock2_1.0.Conv.dwconv.act.zero_point', 'ConvBlock2_1.0.Conv.dwconv.act.init_state', 'ConvBlock2_1.0.Conv.dwconv.act.signed', 'ConvBlock2_1.0.Conv.pwconv2.weight', 'ConvBlock2_1.0.Conv.pwconv2.alpha', 'ConvBlock2_1.0.Conv.pwconv2.init_state', 'ConvBlock2_1.0.Conv.pwconv2.act.alpha', 'ConvBlock2_1.0.Conv.pwconv2.act.zero_point', 'ConvBlock2_1.0.Conv.pwconv2.act.init_state', 'ConvBlock2_1.0.Conv.pwconv2.act.signed', 'ConvBlock2_1.0.Conv.bn2.weight', 'ConvBlock2_1.0.Conv.bn2.bias', 'ConvBlock2_1.0.Conv.bn2.running_mean', 'ConvBlock2_1.0.Conv.bn2.running_var', 'ConvBlock2_1.0.Conv.bn2.num_batches_tracked', 'ConvBlock2_1.0.conv1.weight', 'ConvBlock2_1.0.conv1.alpha', 'ConvBlock2_1.0.conv1.init_state', 'ConvBlock2_1.0.conv1.act.alpha', 'ConvBlock2_1.0.conv1.act.zero_point', 'ConvBlock2_1.0.conv1.act.init_state', 'ConvBlock2_1.0.conv1.act.signed', 'ConvBlock2_1.0.bn1.weight', 'ConvBlock2_1.0.bn1.bias', 'ConvBlock2_1.0.bn1.running_mean', 'ConvBlock2_1.0.bn1.running_var', 'ConvBlock2_1.0.bn1.num_batches_tracked', 'ConvBlock2_1.0.conv2.weight', 'ConvBlock2_1.0.conv2.alpha', 'ConvBlock2_1.0.conv2.init_state', 'ConvBlock2_1.0.conv2.act.alpha', 'ConvBlock2_1.0.conv2.act.zero_point', 'ConvBlock2_1.0.conv2.act.init_state', 'ConvBlock2_1.0.conv2.act.signed', 'ConvBlock2_1.0.bn2.weight', 'ConvBlock2_1.0.bn2.bias', 'ConvBlock2_1.0.bn2.running_mean', 'ConvBlock2_1.0.bn2.running_var', 'ConvBlock2_1.0.bn2.num_batches_tracked', 'ConvBlock2_2.0.Conv.pwconv1.weight', 'ConvBlock2_2.0.Conv.pwconv1.alpha', 'ConvBlock2_2.0.Conv.pwconv1.init_state', 'ConvBlock2_2.0.Conv.pwconv1.act.alpha', 'ConvBlock2_2.0.Conv.pwconv1.act.zero_point', 'ConvBlock2_2.0.Conv.pwconv1.act.init_state', 'ConvBlock2_2.0.Conv.pwconv1.act.signed', 'ConvBlock2_2.0.Conv.bn1.weight', 'ConvBlock2_2.0.Conv.bn1.bias', 'ConvBlock2_2.0.Conv.bn1.running_mean', 'ConvBlock2_2.0.Conv.bn1.running_var', 'ConvBlock2_2.0.Conv.bn1.num_batches_tracked', 'ConvBlock2_2.0.Conv.dwconv.weight', 'ConvBlock2_2.0.Conv.dwconv.alpha', 'ConvBlock2_2.0.Conv.dwconv.init_state', 'ConvBlock2_2.0.Conv.dwconv.act.alpha', 'ConvBlock2_2.0.Conv.dwconv.act.zero_point', 'ConvBlock2_2.0.Conv.dwconv.act.init_state', 'ConvBlock2_2.0.Conv.dwconv.act.signed', 'ConvBlock2_2.0.Conv.pwconv2.weight', 'ConvBlock2_2.0.Conv.pwconv2.alpha', 'ConvBlock2_2.0.Conv.pwconv2.init_state', 'ConvBlock2_2.0.Conv.pwconv2.act.alpha', 'ConvBlock2_2.0.Conv.pwconv2.act.zero_point', 'ConvBlock2_2.0.Conv.pwconv2.act.init_state', 'ConvBlock2_2.0.Conv.pwconv2.act.signed', 'ConvBlock2_2.0.Conv.bn2.weight', 'ConvBlock2_2.0.Conv.bn2.bias', 'ConvBlock2_2.0.Conv.bn2.running_mean', 'ConvBlock2_2.0.Conv.bn2.running_var', 'ConvBlock2_2.0.Conv.bn2.num_batches_tracked', 'ConvBlock2_2.0.conv1.weight', 'ConvBlock2_2.0.conv1.alpha', 'ConvBlock2_2.0.conv1.init_state', 'ConvBlock2_2.0.conv1.act.alpha', 'ConvBlock2_2.0.conv1.act.zero_point', 'ConvBlock2_2.0.conv1.act.init_state', 'ConvBlock2_2.0.conv1.act.signed', 'ConvBlock2_2.0.bn1.weight', 'ConvBlock2_2.0.bn1.bias', 'ConvBlock2_2.0.bn1.running_mean', 'ConvBlock2_2.0.bn1.running_var', 'ConvBlock2_2.0.bn1.num_batches_tracked', 'ConvBlock2_2.0.conv2.weight', 'ConvBlock2_2.0.conv2.alpha', 'ConvBlock2_2.0.conv2.init_state', 'ConvBlock2_2.0.conv2.act.alpha', 'ConvBlock2_2.0.conv2.act.zero_point', 'ConvBlock2_2.0.conv2.act.init_state', 'ConvBlock2_2.0.conv2.act.signed', 'ConvBlock2_2.0.bn2.weight', 'ConvBlock2_2.0.bn2.bias', 'ConvBlock2_2.0.bn2.running_mean', 'ConvBlock2_2.0.bn2.running_var', 'ConvBlock2_2.0.bn2.num_batches_tracked'])
[11:55:07.837247] Conv2dLSQ(
  3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837384] Conv2dLSQ(
  32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837438] Conv2dLSQ(
  64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837480] Conv2dLSQ(
  64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837517] Conv2dLSQ(
  32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837554] Conv2dLSQ(
  128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837589] Conv2dLSQ(
  32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837629] Conv2dLSQ(
  64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837664] Conv2dLSQ(
  128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837697] Conv2dLSQ(
  128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837730] Conv2dLSQ(
  64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837764] Conv2dLSQ(
  256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837798] Conv2dLSQ(
  64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837846] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837878] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837909] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.837946] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838000] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838031] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838061] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838097] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838144] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838178] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838209] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838245] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838291] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838323] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838353] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838389] Conv2dLSQ(
  128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838435] Conv2dLSQ(
  128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838476] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838507] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838537] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838575] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838621] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838652] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838683] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838718] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838763] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838794] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838828] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838865] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838915] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838947] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.838978] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839013] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839059] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839089] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839119] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839155] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839201] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839232] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839261] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839304] Conv2dLSQ(
  256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839348] Conv2dLSQ(
  256, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839387] Conv2dLSQ(
  360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839418] Conv2dLSQ(
  360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839448] Conv2dLSQ(
  360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839483] Conv2dLSQ(
  360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839528] Conv2dLSQ(
  360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839559] Conv2dLSQ(
  360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839589] Conv2dLSQ(
  360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839625] Conv2dLSQ(
  360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
  (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
)
[11:55:07.839676] Using EMA...
[11:55:07.903335] Model = Spiking_vit_MetaFormer_less_conv(
  (downsample1_1): MS_DownSampling(
    (encode_conv): Conv2dLSQ(
      3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
      (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
    )
    (encode_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (ConvBlock1_1): ModuleList(
    (0): MS_ConvBlock(
      (Conv): SepConv(
        (lif1): Multispike()
        (pwconv1): Conv2dLSQ(
          32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (lif2): Multispike()
        (dwconv): Conv2dLSQ(
          64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (pwconv2): Conv2dLSQ(
          64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (lif1): Multispike()
      (conv1): Conv2dLSQ(
        32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
        (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
      )
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (lif2): Multispike()
      (conv2): Conv2dLSQ(
        128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
        (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
      )
      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_2): MS_DownSampling(
    (encode_conv): Conv2dLSQ(
      32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
      (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
    )
    (encode_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_lif): Multispike()
  )
  (ConvBlock1_2): ModuleList(
    (0): MS_ConvBlock(
      (Conv): SepConv(
        (lif1): Multispike()
        (pwconv1): Conv2dLSQ(
          64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (lif2): Multispike()
        (dwconv): Conv2dLSQ(
          128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (pwconv2): Conv2dLSQ(
          128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (lif1): Multispike()
      (conv1): Conv2dLSQ(
        64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
        (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
      )
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (lif2): Multispike()
      (conv2): Conv2dLSQ(
        256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
        (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
      )
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample2): MS_DownSampling(
    (encode_conv): Conv2dLSQ(
      64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
      (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
    )
    (encode_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_lif): Multispike()
  )
  (block2): ModuleList(
    (0-3): 4 x MS_Block(
      (attn): MS_Attention_RepConv_qkv_id(
        (head_lif): Multispike()
        (q_conv): Conv2dLSQ(
          128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (k_conv): Conv2dLSQ(
          128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (v_conv): Conv2dLSQ(
          128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (q_lif): Multispike()
        (k_lif): Multispike()
        (v_lif): Multispike()
        (attn_lif): Multispike_att()
        (proj_conv): Sequential(
          (0): Conv2dLSQ(
            128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (mlp): MS_MLP(
        (fc1_conv): Conv1dLSQ(
          128, 512, kernel_size=(1,), stride=(1,), None
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (fc1_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc1_lif): Multispike()
        (fc2_conv): Conv1dLSQ(
          512, 128, kernel_size=(1,), stride=(1,), None
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (fc2_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc2_lif): Multispike()
      )
    )
  )
  (downsample3): MS_DownSampling(
    (encode_conv): Conv2dLSQ(
      128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
      (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
    )
    (encode_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_lif): Multispike()
  )
  (block3): ModuleList(
    (0-5): 6 x MS_Block(
      (attn): MS_Attention_RepConv_qkv_id(
        (head_lif): Multispike()
        (q_conv): Conv2dLSQ(
          256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (k_conv): Conv2dLSQ(
          256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (v_conv): Conv2dLSQ(
          256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (q_lif): Multispike()
        (k_lif): Multispike()
        (v_lif): Multispike()
        (attn_lif): Multispike_att()
        (proj_conv): Sequential(
          (0): Conv2dLSQ(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (mlp): MS_MLP(
        (fc1_conv): Conv1dLSQ(
          256, 1024, kernel_size=(1,), stride=(1,), None
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc1_lif): Multispike()
        (fc2_conv): Conv1dLSQ(
          1024, 256, kernel_size=(1,), stride=(1,), None
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (fc2_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc2_lif): Multispike()
      )
    )
  )
  (downsample4): MS_DownSampling(
    (encode_conv): Conv2dLSQ(
      256, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
      (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
    )
    (encode_bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (encode_lif): Multispike()
  )
  (block4): ModuleList(
    (0-1): 2 x MS_Block(
      (attn): MS_Attention_RepConv_qkv_id(
        (head_lif): Multispike()
        (q_conv): Conv2dLSQ(
          360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (k_conv): Conv2dLSQ(
          360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (v_conv): Conv2dLSQ(
          360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (q_lif): Multispike()
        (k_lif): Multispike()
        (v_lif): Multispike()
        (attn_lif): Multispike_att()
        (proj_conv): Sequential(
          (0): Conv2dLSQ(
            360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
      )
      (mlp): MS_MLP(
        (fc1_conv): Conv1dLSQ(
          360, 1440, kernel_size=(1,), stride=(1,), None
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (fc1_bn): BatchNorm1d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc1_lif): Multispike()
        (fc2_conv): Conv1dLSQ(
          1440, 360, kernel_size=(1,), stride=(1,), None
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (fc2_bn): BatchNorm1d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (fc2_lif): Multispike()
      )
    )
  )
  (lif): Multispike()
  (head): LinearLSQ(
    in_features=360, out_features=1000, bias=True, {'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>}
    (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
  )
)
[11:55:07.903380] number of params (M): 10.73
[11:55:07.903401] base lr: 3.00e-04
[11:55:07.903413] actual lr: 1.38e-03
[11:55:07.903423] accumulate grad iterations: 1
[11:55:07.903434] effective batch size: 1176
[11:55:07.933022] criterion = LabelSmoothingCrossEntropy()
[11:55:07.933068] DistributedDataParallel(
  (module): Spiking_vit_MetaFormer_less_conv(
    (downsample1_1): MS_DownSampling(
      (encode_conv): Conv2dLSQ(
        3, 32, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
        (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
      )
      (encode_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (ConvBlock1_1): ModuleList(
      (0): MS_ConvBlock(
        (Conv): SepConv(
          (lif1): Multispike()
          (pwconv1): Conv2dLSQ(
            32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (lif2): Multispike()
          (dwconv): Conv2dLSQ(
            64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64, bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (pwconv2): Conv2dLSQ(
            64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (lif1): Multispike()
        (conv1): Conv2dLSQ(
          32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (lif2): Multispike()
        (conv2): Conv2dLSQ(
          128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (downsample1_2): MS_DownSampling(
      (encode_conv): Conv2dLSQ(
        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
        (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
      )
      (encode_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (encode_lif): Multispike()
    )
    (ConvBlock1_2): ModuleList(
      (0): MS_ConvBlock(
        (Conv): SepConv(
          (lif1): Multispike()
          (pwconv1): Conv2dLSQ(
            64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (lif2): Multispike()
          (dwconv): Conv2dLSQ(
            128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128, bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (pwconv2): Conv2dLSQ(
            128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (lif1): Multispike()
        (conv1): Conv2dLSQ(
          64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (lif2): Multispike()
        (conv2): Conv2dLSQ(
          256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
          (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
        )
        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (downsample2): MS_DownSampling(
      (encode_conv): Conv2dLSQ(
        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
        (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
      )
      (encode_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (encode_lif): Multispike()
    )
    (block2): ModuleList(
      (0-3): 4 x MS_Block(
        (attn): MS_Attention_RepConv_qkv_id(
          (head_lif): Multispike()
          (q_conv): Conv2dLSQ(
            128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (k_conv): Conv2dLSQ(
            128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (v_conv): Conv2dLSQ(
            128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (q_lif): Multispike()
          (k_lif): Multispike()
          (v_lif): Multispike()
          (attn_lif): Multispike_att()
          (proj_conv): Sequential(
            (0): Conv2dLSQ(
              128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
              (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
            )
            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (mlp): MS_MLP(
          (fc1_conv): Conv1dLSQ(
            128, 512, kernel_size=(1,), stride=(1,), None
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (fc1_bn): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (fc1_lif): Multispike()
          (fc2_conv): Conv1dLSQ(
            512, 128, kernel_size=(1,), stride=(1,), None
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (fc2_bn): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (fc2_lif): Multispike()
        )
      )
    )
    (downsample3): MS_DownSampling(
      (encode_conv): Conv2dLSQ(
        128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
        (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
      )
      (encode_bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (encode_lif): Multispike()
    )
    (block3): ModuleList(
      (0-5): 6 x MS_Block(
        (attn): MS_Attention_RepConv_qkv_id(
          (head_lif): Multispike()
          (q_conv): Conv2dLSQ(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (k_conv): Conv2dLSQ(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (v_conv): Conv2dLSQ(
            256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (q_lif): Multispike()
          (k_lif): Multispike()
          (v_lif): Multispike()
          (attn_lif): Multispike_att()
          (proj_conv): Sequential(
            (0): Conv2dLSQ(
              256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
              (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
            )
            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (mlp): MS_MLP(
          (fc1_conv): Conv1dLSQ(
            256, 1024, kernel_size=(1,), stride=(1,), None
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (fc1_bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (fc1_lif): Multispike()
          (fc2_conv): Conv1dLSQ(
            1024, 256, kernel_size=(1,), stride=(1,), None
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (fc2_bn): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (fc2_lif): Multispike()
        )
      )
    )
    (downsample4): MS_DownSampling(
      (encode_conv): Conv2dLSQ(
        256, 360, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
        (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
      )
      (encode_bn): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (encode_lif): Multispike()
    )
    (block4): ModuleList(
      (0-1): 2 x MS_Block(
        (attn): MS_Attention_RepConv_qkv_id(
          (head_lif): Multispike()
          (q_conv): Conv2dLSQ(
            360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (k_conv): Conv2dLSQ(
            360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (v_conv): Conv2dLSQ(
            360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (q_lif): Multispike()
          (k_lif): Multispike()
          (v_lif): Multispike()
          (attn_lif): Multispike_att()
          (proj_conv): Sequential(
            (0): Conv2dLSQ(
              360, 360, kernel_size=(1, 1), stride=(1, 1), bias=False, {'nbits': 32, 'mode': <Qmodes.kernel_wise: 2>}
              (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
            )
            (1): BatchNorm2d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
        )
        (mlp): MS_MLP(
          (fc1_conv): Conv1dLSQ(
            360, 1440, kernel_size=(1,), stride=(1,), None
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (fc1_bn): BatchNorm1d(1440, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (fc1_lif): Multispike()
          (fc2_conv): Conv1dLSQ(
            1440, 360, kernel_size=(1,), stride=(1,), None
            (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
          )
          (fc2_bn): BatchNorm1d(360, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (fc2_lif): Multispike()
        )
      )
    )
    (lif): Multispike()
    (head): LinearLSQ(
      in_features=360, out_features=1000, bias=True, {'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>}
      (act): ActLSQ({'nbits': 4, 'mode': <Qmodes.kernel_wise: 2>})
    )
  )
)
[11:55:19.707014] Test:  [ 0/43]  eta: 0:08:26  loss: 8.0472 (8.0472)  acc1: 2.5510 (2.5510)  acc5: 3.5714 (3.5714)  time: 11.7689  data: 9.5148  max mem: 5585
